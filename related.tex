There has been a tremendous amount of work on the specification and
verification of hybrid systems, both from the verification community and
the control theory community.  In this section, we describe some of the
prior work in this area, highlighting the commonalities and difference with
our own work.

\section{Hybrid Automata}
Hybrid automata~\cite{Henzinger96theoryhybrid,Lynch03IO} extend traditional
automata with continuous transitions.  The primary reasoning method for
hybrid automata is model checking~\cite{PHAVerSTTT08,HyTechCAV97}.  There
have been a number of highly successful implementations such as
\textsf{HyTech}~\cite{HyTechCAV97}, \textsf{PHAVer}~\cite{PHAVerSTTT08},
Flow*~\cite{chen2015flow}, and dReach~\cite{kong2015dreach}. While these
are powerful tools, reachability is only decidable for a very restricted
class of automata, for example rectangular automata~\cite{HenzingerKPV98}.
In practice hybrid system model checkers often struggle with large, complex
systems~\cite{muller2000modelling}. As discussed in
Chapter~\ref{chap:emsoft16}, hybrid system model checkers cope with the
complexity by either verifying weaker properties (e.g. bounded safety,
concrete bounds on quantifiers) or by limiting the structure and arithmetic
operators within both discrete and continuous transitions. As noted in that
chapter, the modularity rules presented in that chapter can complement
automated tools by providing a mechanism to decompose a system into
components that are in range for full automation. Making this connection
formal is an interesting direction for future work.

Alur \emph{et al.}~\cite{alur1997modularity} present rules for conjoining
hybrid automata with syntactically independent interface variables and for
renaming variables. Our substitution rules generalize substitution
in~\cite{alur1997modularity} to allow substituting \emph{expressions} for
variables, requiring us to separately justify \progress{} through
invertibility of substitution.  Moreover, different modules often need to
output to the same actuators, and our work pushes beyond the restriction of
syntactically independent variables.  Finally,
unlike~\cite{alur1997modularity}, we present rules for disjunctive
composition.

There has also been work on hybrid automata, model checking, and other
automation techniques specialized to sampled-data systems. We defer
discussion of this work to Section~\ref{sec:related-sampled}.

\section{Deductive logics}
Hybrid systems have been formalized in proof assistants, including the HHL
prover~\cite{LiuHHL10,WangHHL2015} and using Platzer's differential dynamic
logic (\dL{}) in KeYmaera X~\cite{KeYmaeraX}. This section focuses heavily
on \dL{} as it is the most developed logic for hybrid systems
(\ref{sec:related-logic-dl}). We also provide a discussion of HHL and other
work formalizing hybrid systems in general purpose proof assistants
(\ref{sec:related-logic-other}).

\subsection{Differential Dynamic Logic}
\label{sec:related-logic-dl}
The \dL{} logic provides a complete proof
calculus~\cite{Platzer15substitution} for hybrid systems with compositional
proof rules similar to Hoare logic~\cite{hoare1971find}.  It has been
implemented in the KeYmaera X proof assistant~\cite{KeYmaeraX} and applied
to a large number of case studies,
including~\cite{platzercruise11,platzer2009formal,platzerrobots13,Arechiga12refinement}.

The work in Chapter~\ref{chap:memo15} complements the \dL{} logic with an
induction rule specific to sampled-data systems (rather than arbitrary
hybrid systems) as well as an acyclic parallel composition proof rule,
applied to compose sensor error/delay compensation modules with safety
controllers. In addition, that work gives the first formal verification of
a continuous induction rule (i.e. differential
induction~\cite{platzer2010logical,Platzer10DAL}). While the work of this
dissertation was done in a different logic (LTL for
Chapters~\ref{chap:memo15} and~\ref{chap:emsoft16} and a trajectory logic
for Chapter~\ref{chap:exp-smpl}), we believe that all rules can be adapted
to \dL{}. Doing so is an interested direction for future work, as it will
allow a user to reap the benefits of the generality of \dL{} with the
domain specific proof rules of this dissertation, all in a fully formal
context.

The work in Chapter~\ref{chap:emsoft16} further complements \dL{}'s general
proof calculus with rules for building sampled-data systems modularly.
\dL{} is not as expressive as Coq's logic, and some of the proof rules from
Chapter~\ref{chap:emsoft16} are not expressible in \dL{}, namely those with
side conditions (\emph{e.g.}  invertible substitutions, disjointness of
primed variables).  The only way to add these rules to KeYmaera X would be
to extend its core with soundness-critical checking of side conditions or
to employ potentially slow and brittle tactics to prove soundness of
composition on a case-by-case basis.  By working in Coq, we are able to get
higher-order modular \emph{theorems} without compromising soundness.

Since publication of the work in Chapters~\ref{chap:memo15}
and~\ref{chap:emsoft16}, there has been work on embedding \dL{} in the Coq
and Isabelle proof assistants~\cite{Bohrer17-verified-dl}. This is a first
step towards extending \dL{} with the types of domain-specific proof rules
found in this dissertation, without compromising soundness. The Coq and
Isabelle embeddings in ~\cite{Bohrer17-verified-dl} deep embeddings, both
of the logic's syntax and of the proof theory. This was necessary in order
to extract a verified version of the KeYmaera X kernel. On the other hand,
the work in Chapters~\ref{chap:memo15} and~\ref{chap:emsoft16} used a deep
embedding of the syntax but not the proof theory, while the work in
Chapter~\ref{chap:exp-smpl} used a fully shallow embedding of the
logic. Thus, all of the work in this dissertation uses Coq's kernel as the
proof checking core rather than having a separate verified proof checking
kernel. Having a range of embeddings within the same domain could
ultimately permit an evaluation of which embedding is optimal for extending
the proof calculus with higher-order domain-specific proof rules whose side
conditions are not expressible within the object logic (e.g. \dL{}).

After publication of the work in Chapters~\ref{chap:memo15}, there was work
in \dL{} on composition~\cite{Muller16comp,Muller17comp} of hybrid
systems. The authors provide a form of parallel composition of components,
allowing components to interact via ports satisfying input and output
contracts. Unlike the work in Chapter~\ref{chap:emsoft16}, their framework
explicitly disallows components from outputting to the same variables. This
makes the paper most comparable to the composition rule
(Theorem~\ref{thm:sys-compose}) from Chapter~\ref{chap:memo15}. The
framework from~\cite{Muller16comp,Muller17comp} does remove the restriction
to acyclic composition from Theorem~\ref{thm:sys-compose}. However,
parallel composition in that framework is not an associative operation,
while it is in Chapter~\ref{chap:memo15}. This restricts the flexibility of
a user in building and composing more than two modules, as we did in
Section~\ref{sec:delay-comp}. Moreover, the work
from~\cite{Muller16comp,Muller17comp} was not done in a higher-order proof
assistant. Thus, the theorem is applied in KeYmaera X using an untrusted
proof tactic. While this does not compromise soundness, it results in
potentially slow and brittle proofs relative to application of a theorem in
a proof assistant like Coq.

Finally, the main application result from Chapter~\ref{chap:exp-smpl}
(Theorem~\ref{thm:x-bound-dbl-int}), while provable in \dL{}, would require
a combination of proof rules including differential induction and
differential auxiliaries to emulate exponential barrier certificates and a
number of discrete rules to handle the discrete transitions introduced by
the sampled-data model. Most significantly, there is no proof rule that
allows the control to be treated as continuous while separately bounding
the error introduced by this approximation. Thus, we complement the general
\dL{} calculus with powerful higher order proof rules that abstract common
and natural reasoning patterns for sampled-data systems. Again, working in
Coq allows us to add these rules as theorems so that we do not compromise
soundness.

\subsection{Other Logics}
\label{sec:related-logic-other}
The HHL prover~\cite{LiuHHL10,WangHHL2015} is an Isabelle/HOL embedding of
Hybrid Hoare logic. Like KeYmaera X, the HHL prover provides a general
proof calculus for hybrid systems but does not contain domain-specific
proof rules like the ones in this dissertation for sampled-data
systems. Moreover, the embedding does not contain any rules for verifying
invariants of continuous flows. Instead, the prover relies on external
decision procedures that automatically search for invariants. The prover
assumes that invariants returned by these decision procedures are
valid. Thus, formalizing theorems for checking invariants of continuous
flows, as we have done throughout this dissertation, complements the
decision procedures by preventing a bug in the decision procedures from
compromising soundness. Instead, theorems like
Theorem~\ref{thm:barrier-smpl-weak} from Chapter~\ref{chap:exp-smpl} check
the output of decision procedures that produce invariants.

Other work formalizing hybrid systems in general-purpose proof assistants
includes~\cite{volker2000towards,mumm-hybrid-pvs,Niqui2008,GeuversKSW10,Collins10ataylor,anand2015roscoq,arechigainvcuts15,Bohrer17-verified-dl}.
With the exception of~\cite{Bohrer17-verified-dl}, none of this work
includes formalization of \emph{continuous} induction rules like barrier
certificates and differential induction or modular proof rules like the
ones from Chapters~\ref{chap:memo15} and~\ref{chap:emsoft16}. In addition,
the work in Chapter~\ref{chap:exp-smpl} is the first to formalize the
powerful exponential condition form of barrier certificates and the first
to adapt it to sampled-data systems.

\subsection{Temporal Logic}
The foundation for Chapters~\ref{chap:memo15} and~\ref{chap:emsoft16} is
temporal logic, and there has been a lot of work on composition in temporal
logic, most notably by Abadi and
Lamport~\cite{abadi1995conjoin,abadi1994realtime}.  Their work describes
how to reason about the conjunction of LTL specifications, but they do not
deal with the interplay between conjunction and \progress{} or substitution
and \progress{}.  It is important to note that the preservation/\progress{}
split is not the same as the safety/liveness split as both preservation and
progress are safety properties.  Abadi and Lamport address Zeno
specifications in~\cite{abadi1994realtime}, but do not address the
relationship between Zenoness and conjunction.  Finally, neither of these
works addresses substitution in the presence of progress.  It is also
important to note that we use disjunction for non-deterministic choice
between controllers while much of the work in temporal logic uses
disjunction to represent interleaving specifications of asynchronous
concurrent systems.  Other work includes techniques for decomposing LTL
verification into a search for suitable barrier
certificates~\cite{wongpiromsarntemporal15} and deductive rules for
synthesizing controllers satisfying ATL* properties~\cite{dimitrovaATL14}.
While these approaches apply to more temporal logic formulas than ours,
they do not address verification using conjunction, disjunction, and
substitution.  There has also been work on synthesis using approximate
bisimulations~\cite{tabuada08approx}.  We focus on the complementary task
of composing and reusing controllers.

\section{Architectures for Cyber-physical Systems}
In Chapters~\ref{chap:memo15} and~\ref{chap:emsoft16}, we describe how to
architect hybrid systems in order to ensure safety in the presence of
complex, unverified controllers.  There has been prior work in this area,
much of it based on the simplex architecture~\cite{sha1996evolving}.  In
this architecture, there is a simple module that constantly monitors the
system and takes control away from more complex modules before the system
can enter an unsafe state.  We follow a similar principle with our
controller architecture from those two chapters. Our work complements that
based on~\cite{sha1996evolving} by formally verifying the simple monitoring
module (our controllers) rather than relying on their simplicity for
correctness.

Livadas and Lynch solve a similar problem using hybrid I/O automata to
model and reason about ``protectors'' for hybrid systems~\cite{LivadasL98}.
A protector is designed to ensure a safety property of a particular hybrid
system. Livadas and Lynch present a series of rules for conjunctive
composition of protectors.  In contrast, our work also supports other forms
of composition, \textit{e.g.} disjunctive composition, and we show how
these operators can be \emph{combined} to achieve modular verification.

Our system architecture from Chapter~\ref{chap:memo15} is closely related
to the ModelPlex framework in~\cite{mitsch2014modelplex}. This framework
allows a user to produce provably correct runtime monitors for hybrid
systems. These monitors check the execution of a hybrid system
implementation for compliance to a model. If the implementation deviates
from the model, then any safety properties with respect to that model are
no longer guaranteed. In this case, the monitor provides a mechanism for
switching to a fail-safe controller. ModelPlex requires that the safety of
these fail-safe controllers be verified using other techniques. Thus, the
work in this dissertation complements ModelPlex by providing
domain-specific proof rules for verifying fail-safe controllers for
sampled-data systems.

Our theory from Chapter~\ref{chap:emsoft16} is closely related to the work
on modular construction of nonblocking supervisory controllers in
discrete-event systems~\cite{wonham1988supervisory}.  However, our
models explicitly include differential equations rather than requiring a
discrete abstraction and do not require a notion of termination in a marked
state.  Moreover, to the best of our knowledge, none of this work makes the
inductive invariant explicit and separates preservation from \progress{}.

Finally, the area of switching control~\cite{liberzon2012switching} from
control theory focuses on (in our terminology) disjunctive composition of
controllers.  Our inclusion of invariants in the discrete controller
corresponds to expressing the switching boundary in a switching controller.
However, the focus of switching control theory is optimality, stability,
and transitionability, whereas we focus on complementary properties like
bounding the state space.
%TODO read more about switching control

\subsection{Geofences}
There has been research on keeping UAVs in a designated safe area, and more
generally on obstacle avoidance strategies for UAVs. The most related work
is the recent geofencing strategy developed by Gurriet et
al~\cite{gurriet16geofence}. This work places constraints on a pilot's
desired velocity vector to avoid leaving a specified safe region. The
strategy is complementary to the one described in this paper as it leaves
the maximum velocity in a given direction unspecified. Future work can
explore composing their strategy with the concrete velocity constraints
described in Chapter~\ref{chap:exp-smpl}.

\section{Inductive Methods for Continuous and Hybrid Systems}
There is a long history of techniques for establishing forward invariance
of systems of differential equations.\footnote{A set $S$ is forward
  invariant with respect to a system of differential equations if every
  solution starting in $S$ remains in $S$.} One of the earliest such
techniques is known as Nagumo's viability
theorem~\cite{aubin2009viability}. This technique relies on a notion called
the tangent cone of a set at a point. Informally, the tangent cone of a set
$S$ at a point $x$ is the set of all vectors starting from $x$ that point
inward towards $S$. Nagumo's viability theorem states that a closed set $S$
is forward invariance with respect to a system of differential equations
$\dt{\vecbold{x}} = f(\vecbold{x})$, if at all points $\vecbold{x}$ on the
boundary of $S$, $f(\vecbold{x})$ is contained in the tangent cone of
$\vecbold{x}$ at $S$. Such a semantic condition for invariance is powerful,
as it applies to arbitrary closed sets. However, it is difficult to apply
in practice without an effective way of computing the tangent cone of a
particular closed set at a point.

Since Nagumo's theorem, a number of techniques have been developed that
establish forward invariance of particular classes of
sets. In~\cite{prajna04barrier}, Prajna \emph{et al.} coined the term
barrier certificates and showed that for a differentiable function $B$, $B
\leq 0$ is forward invariant with respect to a system of differential
equations if the Lie derivative of $B$ along the vector field of that
system is negative at $B = 0$.\footnote{The Lie derivative of $B$ along the
  vector field $f(\vecbold{x})$ is defined by $\nabla B \dotprod f$ and
  gives the rate of change along solutions of the system $\dt{\vecbold{x}}
  = f(\vecbold{x})$}. The premise $B=0$ in this rule comes with a number of
drawbacks. First, as the authors note in~\cite{prajna04barrier}, it renders
the set of barrier certificates non-convex, making it inefficient to
automatically search for barrier certificates for a given system. Second,
as is explored in~\cite{Ghorbal17inv}, this premise makes it challenging to
generalize the rule to sets built using finite boolean combinations of
polynomial inequalities. Finally, only considering the Lie derivative of
$B$ exactly at the boundary of the set prevents the rule from being
extended to sampled-data systems using the approach we employ in
Chapter~\ref{chap:exp-smpl}. Because of the first reason, the authors
of~\cite{prajna04barrier} also give a formulation of barrier certificates
without the premise $B = 0$.

Platzer's differential induction~\cite{platzer2010logical,Platzer10DAL}
provides a generalization of this weaker formulation of barrier
certificates (without the premise $B = 0$) to finite boolean combinations
of polynomial inequalities. The total differential operator
from~\cite{platzer2010logical,Platzer10DAL} and the more recent rewrite
rule-based formulation from~\cite{Platzer15substitution} provide an
automatic mechanism for computing Lie-derivatives of finite boolean
combinations of polynomial inequalities. This automation is very useful but
fails to handle piecewise functions as we do in
Chapter~\ref{chap:exp-smpl}. In addition, differential induction does not
generalize the more powerful exponential condition-based barrier
certificates from~\cite{kong2013barrier} that we use in
Chapter~\ref{chap:exp-smpl}. Instead, differential induction must be
augmented with differential auxiliaries~\cite{Platzer12diffcut} to handle
systems that exponentially decay towards the invariant boundary. Most
significantly, the exponential condition-based barrier certificates provide
a natural mechanism for quantifying the invariant violation from a
continuous-time approximation of a sampled-data system, as we do in
Chapter~\ref{chap:exp-smpl}. It is not clear how to do this with
differential induction, as the condition for this proof rule does not imply
that trajectories of the system move towards the invariant region when they
start outside (i.e. after a violation).

Recent work from the control theory community has produced rules that are
less conservative than differential induction for inequalities (not boolean
combinations). In~\cite{kong2013barrier}, Kong \emph{et al.} present
exponential condition-based barrier certificates that we adapt in
Chapter~\ref{chap:exp-smpl}. In~\cite{ames2016control} Ames \emph{et al.}
present what they term reciprocal barrier functions. Rather than going to
zero at the invariant boundary, these functions become unbounded at the
invariant boundary. As noted in~\cite{xu15barrier}, this makes reciprocal
barrier functions unsuited for verifying robust safety properties, as
modeling error can result in a trajectory reaching a state in which the
barrier function is undefined. Barrier Lyapunov
functions~\cite{Tee09ctrlbarrier} suffer from the same robustness issue as
they too grow to infinity at the invariant boundary. Our adaptation of
barrier certificates to sampled-data systems in Chapter~\ref{chap:exp-smpl}
can be viewed as a robustness property -- modeling error is introduced by a
continuous time approximation of the controller. However, neither of the
robustness notions covered in~\cite{xu15barrier} are sufficient for
sampled-data systems as they do not address additive control disturbances.

Taly and Tiwari~\cite{taly2009deductive} present a number of induction
rules based on the Lie derivative that are complete for various classes of
invariants. They focus on rules that are effectively computable, in
contrast with Nagumo's theorem. However, all of their rules consider the
Lie derivative only at the boundary of the invariant set. As
in~\cite{prajna04barrier}, this makes them unsuited for reasoning about
robust safety since disturbances can push the system outside the boundary
of the invariant set. The premises of the rules in~\cite{taly2009deductive}
express nothing about the behavior of the system after such
violations. Similarly,~\cite{Liu11barrier} presents a necessary and
complete rule that only considers points at the boundary of the invariant
set. For our setting, this suffers from the same drawback
as~\cite{taly2009deductive}.

In~\cite{Ghorbal17inv}, Ghorbal, Sogokon, and Platzer explore the relative
deductive power of a number of the above rules for verifying positive
invariance. They also present a mechanism for reasoning about Lie
derivatives of piecewise functions. In contrast with our handling of
piecewise functions in Chapter~\ref{chap:exp-smpl}, the mechanism
from~\cite{Ghorbal17inv} can handle piecewise functions that are not
everywhere differentiable. However, the mechanism does not apply to
exponential condition-based barrier certificates, and thus would be
unsuitable for sampled-data systems. Moreover, this mechanism has not been
implemented in a formal verification framework like Coq.

Very recently, Dai \emph{et al.}~\cite{Dai17revisited} have proposed a
generalization of exponential condition-based barrier certificates
from~\cite{kong2013barrier}. In particular, rather than showing that the
Lie derivative of the barrier function is at most proportional to its
value, one shows that the Lie derivative is at most a polynomial function
of its value for an appropriately chosen polynomial. The authors present a
family of such polynomials, for which the condition
from~\cite{kong2013barrier} is a special case. In related work, Zeng
\emph{et al.}~\cite{Zeng16barrier} present a formulation of barrier
functions in which the barrier function must be a Darboux
polynomial.\footnote{$B$ is a Darboux polynomial with respect to the vector
  field $f(\vecbold{x})$ if $\nabla B \dotprod f = c(\vecbold{x}) \cdot
  B(\vecbold{x})$ for some polynomial $c$}. These papers raise an
interesting direction for future work: can such techniques be adapted to
sampled-data systems to produce a more powerful proof rule than that in
Chapter~\ref{chap:exp-smpl}?

Some of the work in this
section~\cite{Dai17revisited,kong2013barrier,Zeng16barrier} also presents
automation for generating polynomial inequalities satisfying their
respective barrier function conditions. Since it is designed for continuous
time systems, the automation from~\cite{kong2013barrier} could be applied
directly to satisfy condition~\eqref{thm:barrier-smpl-exp} of
Theorem~\ref{thm:barrier-smpl} in Chapter~\ref{chap:exp-smpl}. We did not
need this automation as we were able to design a barrier function
manually. However, this connection provides evidence for the value of
Theorem~\ref{thm:barrier-smpl}. By decomposing the problem into an
intersample property and a property of the continuous time approximation,
we are able to take advantage of control theory techniques for continuous
time. Also, our work in Chapter~\ref{chap:emsoft16} is complementary to
this automation -- the theorems in that chapter provide a mechanism for
decomposing problems into more manageable components to address scalability
issues.

The work in~\cite{ames2016control,xu15barrier} also gives the notion of a
control barrier function, a technique for synthesizing a controller from a
barrier function. In this technique, the controller is initially left
unspecified and later synthesized from the barrier certificate condition,
e.g. the exponential condition from~\cite{kong2013barrier}. This is
essentially the technique we used in building
assumption~\ref{ass:u_pw_bound} from Chapter~\ref{chap:exp-smpl}.

Related to the modularity rules in Chapter~\ref{chap:emsoft16}, a recent
paper~\cite{xu16sharing} addresses the challenge of composing two control
barrier functions in a way that ensures a controller exists satisfying both
conditions. This is analogous to our conjunctive composition. The key
property is called control sharing and is related to \progress{} from
Chapter~\ref{chap:emsoft16}. The technique from that paper only applies to
two control barrier functions and continuous time controllers. However,
generalizing it to an arbitrary number of controllers and combining it with
our Theorem~\ref{thm:barrier-smpl} from Chapter~\ref{chap:exp-smpl} could
provide an alternate technique for conjunctive composition of sampled-data
systems.

Sloth \emph{et al.}\cite{Sloth12composition} also present a mechanism for
compositional verification of continuous time systems using barrier
certificates. In addition to focusing on continuous time systems rather
than sampled-data systems, this work differs from parallel composition in
Chapter~\ref{chap:emsoft16} by considering systems whose components
interact via interconnection inputs rather than by sharing a single control
input that must satisfy a composition of inequalities.

It is important to note that the only formal implementation of any of the
inductive conditions in this section is Platzer's differential induction in
the KeYmaera X proof assistant~\cite{KeYmaeraX}. Implementing these
conditions formally is important. As noted in~\cite{taly2009deductive},
unsound continuous induction rules have been published and used before
their unsoundness was discovered.

Finally, some of the above
approaches~\cite{prajna04barrier,kong2013barrier} also have generalizations
to arbitrary hybrid systems to ensure that the barrier certificate changes
value appropriately after discrete transitions of the system. While
powerful, these rules do not allow one to verify the controller with
respect to a continuous time approximation and separately reason about the
error introduced by this approximation, as we do in
Chapter~\ref{chap:exp-smpl}. Instead, the controller must explicitly take
into account intersample behavior in order to ensure that the barrier
certificate satisfies the appropriate condition between samples.

\section{Sampled-Data Systems}
\label{sec:related-sampled}
Barrier functions are part of a general class of functions called storage
functions~\cite{Willems1972} that are used to reason about dynamical
systems by assigning a scalar value to each state and analyzing how the
value of the functions dissipates along trajectories of the system.  There
has been a variety of work on storage function approaches for reasoning
about sampled-data systems.  Much of this work,
including~\cite{chen1991input,seuret13sampled}, focuses on stability of
sampled-data systems using Lyapunov or Lyapunov-like functions, which is an
important but orthogonal concern. The most relevant to this dissertation is
the work by Laila, Ne\v si\'c, and Teel~\cite{laila02sampled} on a
general framework for analyzing the behavior of dissipation inequalities
for sampled-data systems. The exponential condition-based barrier functions
from~\cite{kong2013barrier}, which we adapt in Chapter~\ref{chap:exp-smpl},
are a particular type of dissipation inequality. The framework
in~\cite{laila02sampled} applies to controllers that are designed using
emulation: the controller is designed with respect to a continuous time
approximation of the system and the implemented digitally in a sampled-data
system. The authors then provide a series of theorems that quantify the
effect of emulation on dissipation inequalities. This is essentially the
same approach as Theorem~\ref{thm:barrier-smpl} in
Chapter~\ref{chap:exp-smpl}. The framework in~\cite{laila02sampled} is far
more general than our model in Chapter~\ref{chap:exp-smpl}, as it handles
disturbances, controllers that maintain state, etc. However, the theorems
in~\cite{laila02sampled}, when specialized to exponential condition-based
barrier certificates and our less general model of sampled-data systems,
apply only to states bounded by some constant magnitude. This restriction
is not required by Theorem~\ref{thm:barrier-smpl}. Moreover, none of the
work in~\cite{laila02sampled} has been formalized in a proof assistant like
Coq. Finally, the theorems in~\cite{laila02sampled} only give deviation
bounds of dissipation inequalities over a single sampling period, while
Theorem~\ref{thm:barrier-smpl} quantifies how much the deviation over a
single sampling period affects the invariant violation over an infinite
time horizon. Nevertheless, real systems often permit conservative constant
bounds on the magnitude of the state, and it would be interesting to
formalize the framework of~\cite{laila02sampled} in Coq and extend it to
infinite time horizons to determine how the violation bounds compare to
those of Theorem~\ref{thm:barrier-smpl}.

Some work analyzes sampled-data systems by treating them as time-delay
systems~\cite{Fridman04delay}.  Prajna \emph{et al.} adapted their barrier
certificate formulation to time delay
systems~\cite{prajna05delay}. However, the model of time delay systems
in~\cite{prajna05delay} is not as general as~\cite{Fridman04delay} and
crucially cannot express systems with discontinuous delay, which is
necessary for sampled-data systems.

There has also been work on algorithms for computing the discriminating
kernel\footnote{The discriminating kernel is sometimes known as the
  viability kernel.} of a sampled-data systems for an invariant
set~\cite{mitchell2015improved,mitchell2013safety,Gillula14sampled}. The
discriminating kernel characterizes the set of initial states of the system
for which there exists a control law that keeps all trajectories inside the
invariant set.  The algorithms
in~\cite{mitchell2015improved,Gillula14sampled} only compute the
discriminating kernel for a finite time horizon and thus provides a weaker
guarantee than the infinite horizon safety guarantees in this
dissertation. The algorithm in~\cite{mitchell2013safety} can, in certain
cases reach a fixed point thus guaranteeing safety over an infinite time
horizon. However, there are no characterization of the class of systems for
which such a fixed point will be reached. In addition, formalizing
soundness of the algorithms from these papers in a proof assistant would be
challenging, as they do not produce a witness that can be efficiently
checked for correctness, as in the case of algorithms for generating
barrier certificates~\cite{Dai17revisited,kong2013barrier,Zeng16barrier}.

Model checking has also been employed specifically for sampled-data
systems. In~\cite{silva01sampled}, Silva and Krogh present sampled-data
hybrid automata -- the specialized model permits a more efficient model
checking algorithm using the \emph{CheckMate} model
checker~\cite{silva2000modeling} than general purpose hybrid system model
checkers. However, the model checker can only guarantee safety over a
finite time horizon. Similarly, in~\cite{simko14bmc}, Simko and Jackson
present a model checking algorithm for sampled-data systems that is based
on Taylor models of the continuous dynamics and SMT solvers rather than
automata. Their algorithm also only guarantees safety over a finite time
horizon.

An alternate approach for verifying safety of sampled-data systems was
explored in~\cite{Zutshi12sampled} based on timed relational
abstractions. In this approach, automation constructs relations that map
the state of the system at a sample time to the state of the system at the
next sample time. However, this model assumes that the inter sample time is
fixed rather than bounded and more importantly, only verifies properties of
states exactly at the sample times. An additional mechanism would be needed
to verify properties of states between samples.

\section{Acknowledgments}
Thanks to Andr\'e Platzer, Nathan Fulton, and Andrew Sogokon for answering
numerous questions to help put this work in context.

This chapter is adapted from material as it appears in International
Conference on Formal Methods and Models for System Design ~2015.  Ricketts,
Daniel; Malecha, Gregory; Alvarez, Mario~M.; Gowda, Vignesh; Lerner, Sorin,
ACM Press,~2015. International Conference on Embedded Software~2016.
Ricketts, Daniel; Malecha, Gregory; Lerner, Sorin, ACM Press,~2016. The
dissertation author was the primary investigator and author of these
papers.
