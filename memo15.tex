This chapter presents two proof rules for reasoning about sampled-data
systems. The first rule is an induction rule specialized to sampled-data
systems. This rule decomposes an inductive safety proof into a proof about
the initial state, a proof about the discrete transition, and a proof about
the continuous transition. For each of the transitions, the proof rule
introduces timing constraints that are guaranteed by the periodic
sampled-data model. Such a rule automatically manages the aspects of an
inductive safety proof that are common to all periodic sampled-data
systems, allowing the user to focus on the application specific aspects of
the proof. Without such a proof rule, this tedious decomposition would have
to be done manually.

The second rule provides a simple mechanism for composing systems with
non-cyclic dependencies. This allows one component to assume that invariant
of another when proving its own invariant. We demonstrate how this can be
used to reason about systems in the presence of both sensor error and delay
by chaining instances of this rule together. Chapter~\ref{chap:emsoft16}
presents an alternate approach that removes the non-cyclic restriction.

We introduce the proof rules along side a running example: a controller
that prevents a simple model of a quadcopter from violating some maximum
velocity. We additionally used the rules to verify a controller that
prevents a quadcopter from violating some maximum height, and used our
composition rule to verify them both in the presence of sensor error and
delay.

In an effort to ensure that our examples are realistic, we implemented them
on a actual quadcopter and performed flight tests. Doing so forced us to
confront an important issue. Since our controllers are components of a much
larger system containing numerous controllers, how do we architect the
autopilot to incorporate our controllers, while still maintaining our
safety guarantees? Throughout the paper, we describe our solution and
discuss engineering tradeoffs. We also discuss discrepancies between our
model and reality as well as lessons learned from doing foundational
verification of sampled-data systems.

\section{Overview}
We start by giving an overview of how our running controller examples fit
into the architecture of a quadcopter's autopilot. We would like our two
controllers to ensure that a quadcopter does not exceed some maximum
velocity and some maximum height. These are practical restrictions from a
safety standpoint. For example, in order to ensure that small UAVs do not
interfere with larger aircraft, the FAA mandates that they do not fly more
than 400 feet above ground level.

Our goal here will be to (1) add some simple logic to the control software
to prevent violation of these safety properties and (2) formally verify
that this logic guarantees that the safety properties hold, with respect to
some model of the physical dynamics of the UAV.  However, we would like to
accomplish this while allowing the UAV to run its existing complex
controllers that may not guarantee these properties -- these sorts of
controllers have the potential to achieve high performance, but their
complexity presents a challenge to formal verification.

We accomplish this by implementing our controllers as safety checks that
run after all of the (potentially complex) controllers have run, but before
any signals are sent to the motors.  Our controllers perform a safety check
on the outputs from the higher level controllers.  In our height limit
example, the controller checks whether the output of the higher level
controllers would put the UAV in a state in which it could not stop before
exceeding the upper bound.  If the check passes then the controller issues
exactly the same outputs as the higher level controllers.  Otherwise, the
controller issues a conservative action to ensure the desired safety
property.

Our architecture, inspired by the simplex
architecture~\cite{sha1996evolving}, is depicted in
Figure~\ref{fig:arch-shim}, which shows a simplified view of a UAV
architecture with and without our controllers.  This architecture allows us
to focus our verification effort on our safety critical controllers,
without needing to reason about complex existing controllers.  This design
makes the verification tractable, while retaining the benefits of
state-of-the art controllers. We discuss this architecture in more detail
in Section~\ref{sec:arch}.

\begin{figure}[t]
\centering

\begin{subfigure}[t]{.49\linewidth}
  \centering
  \begin{tikzpicture}
    \tikzstyle{every node}=[draw=black,thick,font=\bfseries,node distance=0.35cm]
    \tikzstyle{every path}=[draw=black,thick]
    \tikzstyle{wnode}=[minimum width=1cm]

    \node[wnode,text width=2cm,align=center] (existing)  {Existing Control Software} ;

    \node[draw=black,above=of existing,minimum height=0.5cm,xshift=0.7cm] (user) {User} ;
    \node[draw=black,above=of existing,minimum height=0.6cm,xshift=-1cm] (sensor) {Sensors} ;

    \node[wnode,below=of existing] (motor)  {Motors} ;

    \newcommand{\quadline}[2]{%
    \foreach \i in {-2,...,1}{%
      \draw[-latex] ([xshift=0.12cm + \i * 0.3 cm]#1.south) -- ([xshift=0.12cm + \i * 0.3 cm]#2.north) ;}}

    \quadline{existing}{motor}
    \draw[-latex] let \p1 = (user.south),
                      \p2 = (existing.north) in
                  (user.south) -- (\x1,\y2) ;
    \draw[-latex] let \p1 = (sensor.south),
                      \p2 = (existing.north) in
                  ([xshift=0.2cm]sensor.south) -- (\x1+0.2cm,\y2) ;



  \end{tikzpicture}
  \caption{}
  \label{fig:memo15-arch-without}
\end{subfigure}
~
\begin{subfigure}[t]{.49\linewidth}
  \centering
  \begin{tikzpicture}
    \tikzstyle{every node}=[draw=black,thick,font=\bfseries,node distance=0.35cm]
    \tikzstyle{every path}=[draw=black,thick]
    \tikzstyle{wnode}=[minimum width=1cm]

    \node[fill=black,text=white,text width=2cm,align=center,minimum height=1cm] (mon) at (0,0) {Verified Control} ;
    \node[wnode,above=of mon,text width=2cm,align=center] (existing)  {Existing Control Software} ;

    \node[draw=black,above=of existing,minimum height=0.5cm,xshift=0.7cm] (user) {User} ;
    \node[draw=black,above=of existing,minimum height=0.6cm,xshift=-1cm] (sensor) {Sensors} ;

    \node[wnode,below=of mon] (motor)  {Motors} ;

    \newcommand{\quadline}[2]{%
    \foreach \i in {-2,...,1}{%
      \draw[-latex] ([xshift=0.12cm + \i * 0.3 cm]#1.south) -- ([xshift=0.12cm + \i * 0.3 cm]#2.north) ;}}

    \quadline{mon}{motor}
    \quadline{existing}{mon}
    \draw[-latex] let \p1 = (user.south),
                      \p2 = (existing.north) in
                  (user.south) -- (\x1,\y2) ;
    \draw[-latex] let \p1 = (sensor.south),
                      \p2 = (existing.north) in
                  ([xshift=0.2cm]sensor.south) -- (\x1+0.2cm,\y2) ;
    \draw[-latex] ([xshift=-0.5cm]sensor.south) |- (mon.west) ;


  \end{tikzpicture}
  \caption{}
  \label{fig:memo15-arch-with}
\end{subfigure}

\caption{A simplified depiction of UAV architecture~\ref{fig:memo15-arch-without} without and~\ref{fig:memo15-arch-with} with one of our controllers.}
\label{fig:arch-shim}
\end{figure}

\section{Model and Verification}
\label{sec:memo15-model}
We now focus on our controller that ensures the velocity of a simple
one-dimensional model of a quadcopter never exceeds a constant upper bound
\ub{}. We start by modeling the system using our abstraction \SysA{}
(Definition~\ref{def:sys-abstraction}), present our sampled-data induction
rule, and demonstrate how to use this rule to verify the safety invariant
of the velocity bounding controller. In
Section~\ref{sec:memo15-composition}, we will present our composition rule
and show how to use it to verify safety in the presence of sensor error and
delay.

\subsection{Model}
Our velocity controller makes use of the following variables (by
convention, lower case variables are continuous and upper case variables
are discrete): $\V$ is the actual velocity of the system, whose behavior
will be specified by differential equations encoding the physics of the
real world; $\Vmax$ is an upper bound on $\V$ (e.g. produced by a sensor)
and is an input to our controller; $\Tproposed$ is the thrust requested by the
higher level controller, which is also an input to our controller; $\T$ is the
thrust produced by our controller, which gets sent to the motors. Our controller is
defined as follows:
\[
\VelShim \defined \Sys{D}{\W}{\Delta}
\]
where
\[
\begin{array}{rcl}
\W & \defined & \dt{\V}\leq\T - g \\
D & \defined & ((\Tproposed-g)\cdot\Delta + \Vmax \leq \ub \wedge \T\tlaprime {=} \Tproposed) \vee \T\tlaprime {=} g
\end{array}
\]
$\W$ states the differential inequality capturing how velocity is related
to thrust ($\T$) and gravity ($g$).  This relationship is an inequality
rather than an equality because we are modeling a quadcopter, whose
vertical thrust is only upper-bounded by the thrust produced by the motors.
We discuss this further in Section~\ref{sec:experiences}.  The action
formula $D$ captures the control logic of our controller.  The disjunction
encodes, essentially, the following conditional statement:
$\texttt{if}\,\Tproposed \cdot \Delta + \Vmax \leq
\ub\,\texttt{then}\,\T\tlaprime = \Tproposed\,\texttt{else}\,\T\tlaprime =
g$; though it also allows executing the safe action ($\T\tlaprime = g$)
when the check succeeds.

Since \SysA{} unfolds directly to an LTL formula, we can express the
correctness of our controller directly in LTL as follows, where $\entails$
(Definition~\ref{def:ltl-entails}) represents entailment in LTL, expressing
that the formula to the right of the $\entails$ holds on all traces
satisfying the formula to the left of the $\entails$:
\begin{align}
\label{thm:shim-safe}
\Always{\V \leq \Vmax} \vdash \Init \wedge \VelShim \rightarrow \Always{\V \leq \ub} \\
\Init \defined \max(0,\T - g )\cdot\Delta + \V \leq \ub \nonumber
\end{align}
This formula states that if $\Vmax$ is always an upper bound on the actual
velocity ($\Always{\V \leq \Vmax}$), then the velocity controller ensures
that the velocity of the system is always less than or equal to \ub{}.
This requires a predicate on the initial state, given by \Init, which
states that the velocity is at most \ub{} and furthermore is small enough
that it will still be at most \ub{} when the controller first runs (which
will be at most $\Delta$ time units away).  For now, we do not specify how
the value of $\Vmax$ is produced; that is, $\Vmax$ does not appear in any
action formulas (transitions).  Instead, we simply assume that such a value
is provided to the controller.  In Section~\ref{sec:compose}, we will show
how to specify systems that produce a $\Vmax$ satisfying this assumption
and we will show how to compose them with the velocity controller.

\subsection{Proof}
We now show how we prove the above LTL formula in Coq.  To do so, we need
an inductive invariant that is preserved both by the continuous transitions
(those of the world) and the discrete program.  Although we have
implemented several mechanisms for simplifying reasoning about \SysA{}, we
currently do not infer invariants automatically. In the case of the
velocity controller, the inductive invariant is relatively simple: the
velocity cannot violate the upper bound before the next execution of the
controller:
\[
\max(0,\T - g)*\Time + \V \leq \ub
\]
Here, the variable \Time{}, introduced in
Definition~\ref{def:sys-abstraction} tracks the maximum amount of time
until the next execution of the controller.

In order to prove that this formula is an inductive invariant, we use the
the \textsc{SysInd} proof rule (Theorem~\ref{thm:sys-ind}), which is a
special case of discrete induction tailored to systems that are described
by our \SysA{} construct.  Proof rules such as this one allow us to
abstract the implementation of \SysA{} and make for overall cleaner proofs.
Informally, \textsc{SysInd} states that a formula $P$ is an (inductive)
invariant of a system if $P$ holds on all possible initial states of the
system, and $P$ is preserved by the two possible transitions that the
system can make.  We use $P\tlaprime$ to denote the formula $P$ with all
unprimed variables $\tlavar{x}$ replaced with their primed counterpart
$\tlanextvar{x}$.

\begin{theorem}[\textsc{SysInd}]
For state formulas $P,Q,I$, action formula $D$, constant $\Delta \in \R$,
and evolution predicate $\W$, if the following conditions hold:

\begin{enumerate}[label=\roman*), ref=\roman*]
\item
\label{thm:sys-ind-init}
$Q~\entails 0 \leq \Time \leq \Delta~\wedge~I \rightarrow P$
\item
\label{thm:sys-ind-discr}
$Q~\entails 0 \leq \Time{} \leq \Delta~\wedge~P~\wedge~D~\wedge~\tlanextvar{\Time{}} = \Time{} \rightarrow \Next{P}$
\item
\label{thm:sys-ind-cont}
$Q~\entails \Time \leq \Delta~\wedge~0 \leq \tlanextvar{\Time}~\wedge~P~\wedge~\Continuous{(\W)} \rightarrow \Next{P}$
\end{enumerate}
then
\[
\Always{Q}~\entails I~\wedge~\Sys{D}{\W}{\Delta} \rightarrow \Always{P}
\]
\label{thm:sys-ind}
\end{theorem}

To illustrate how the proof works, we walk through the proof obligations
obtained by applying \textsc{SysInd} to our velocity controller.  First, we
must prove that $P$ holds on all initial states of the system:
\[
\begin{array}{lc}
\V \leq \Vmax & \vdash \left[
\begin{array}{ll}
& 0 \leq \Time \leq \Delta \\
\wedge & \max(0,\T - g )\cdot\Delta + \V \leq \ub \\
\rightarrow & \max(0,\T - g)\cdot\Time + \V \leq \ub
\end{array}
\right]
\end{array}
\]
Proving this requires first order reasoning over real arithmetic in Coq.
We can solve simple obligations such as this one, using existing Coq real
arithmetic decision procedures~\cite{besson2007micromega} that produce
foundational Coq proofs completely automatically.  While these procedures
are not complete, they are still able to discharge many obligations that
arise in practice.  When they are unable to completely prove a goal, we are
forced to manually construct a machine-checked proof of the remaining
obligations. This requires manual application of real arithmetic lemmas
such as transitivity of comparison operators. This can become quite tedious
as the system becomes more complex.  The compositional reasoning
techniques, which we describe in Section~\ref{sec:memo15-composition}, help
to reduce this burden by producing smaller arithmetic goals that only deal
with a part of the system. We discuss this benefit in more detail in
Section~\ref{sec:height-shim}.

Next, we prove that the inductive invariant is preserved by discrete steps
of the system.  There are actually two cases to prove: when the proposed
thrust passes the controller's safety check and when the controller issues
a thrust equal to gravity.  In the first case, we are left to prove the
following proof obligation (the reasoning in the second case is simpler):
\[
\begin{array}{lc}
\V \leq \Vmax & \vdash \left[
\begin{array}{ll}
& 0 \leq \Time \leq \Delta \\
\wedge & \max(0,\T - g)*\Time + \V \leq \ub \\
\wedge & (\Tproposed-g)*\Delta + \Vmax \leq \ub \\
\wedge & \T\tlaprime = \Tproposed  \\
\wedge & \V\tlaprime = \V \\
\wedge & \Time\tlaprime = \Time \\
\rightarrow & \max(0,\T\tlaprime - g)*\Time\tlaprime + \V\tlaprime \leq \ub
\end{array}
\right]
\end{array}
\]
Proving this obligation requires first order reasoning over real
arithmetic, but fits into the automation described above.

Finally, we prove that the inductive invariant is preserved by continuous
transitions.  This proof obligation is slightly more difficult:
\[
\begin{array}{lc}
\V \leq \Vmax & \vdash \left[
\begin{array}{ll}
& \Time \leq \Delta \wedge 0 \leq \Time\tlaprime \\
\wedge & \max(0,\T - g)\cdot\Time + \V \leq \ub \\
\wedge & \Continuous{(\W)} \\
\rightarrow & \max(0,\T\tlaprime - g)\cdot\Time\tlaprime + \V\tlaprime \leq \ub
\end{array}
\right]
\end{array}
\]
Continuous evolution of the physical world is expressed by the formula
$\Continuous{(\W)}$ (Definition~\ref{def:continuous}). We prove this
obligation using our adaptation of Platzer's differential induction proof
rule~\cite{platzer2010logical}, which justifies a technique for proving
invariants of a system of differential equations without computing an
explicit solution.  Roughly speaking, differential induction captures the
fact that $e_1 \leq e_2$ is preserved by a continuous transition
(e.g. $\Continuous{(\W)}$) if the derivative of $e_1$ is less than or equal
to the derivative of $e_2$, under the constraints given by $\W$.  Applying
differential induction leaves us to prove a first order formula over real
arithmetic that the automation can solve with a minimal amount of
assistance.

Proving these four goals completes the proof
of~\eqref{thm:shim-safe}. Since the inductive invariant was simple and the
arithmetic reasoning was within the scope of Coq's built-in automation,
this proof was relatively easy. However, the proof demonstrates the general
mechanics of proving an invariant of a periodic sampled-data system and
illustrates how \textsc{SysInd} abstracts some of the tedious reasoning
common to all such systems.

\section{Composition}
\label{sec:memo15-composition}
While the velocity controller does guarantee the safety property, it
requires an assumption about an input, namely that $\V \leq \Vmax$.  We
could modify the specification of the velocity controller so that it
specifies the transition behavior of $\Vmax$ in a way that guarantees that
$\V \leq \Vmax$, thus removing the assumption.  That is, we could modify
the controller specification to show how $\Vmax$ is produced by adding
$\Vmax$ to action formulas of the specification.  However, this would
require reproving the safety theorem of the velocity controller
(formula~\eqref{thm:shim-safe}).  By leaving the sensor under-specified in
the velocity controller, we are able to compose the velocity controller
with \emph{any} system that guarantees $\Always{\V \leq \Vmax}$, without
needing to reprove the safety theorem of the velocity controller.  In this
section, we show how to do this for several examples, using a general
composition rule for our \SysA{} abstraction.

\subsection{Sensor Error}
Real sensors always have some notion of error.  For example, the readings
from a barometer may be affected by pressure differences due to local
weather or GPS may only give accurate information to within several feet.
In addition, sensors, detect physical, continuous values and compute
discrete approximations of these values, for example using fixed- or
floating point.  These finite representations can not hope to be exactly
the true values of the variables they represent.  While the first type of
error can be modeled probabilistically, we assume that a sensor can be
assigned a deterministic conservative upper bound on the error. Thus, it is
easy to model both kinds of error in our framework since we only need to
specify predicates on the sensed values.

We start with a simple specification of a sensor that can read the value of
$\V$ to within some error $\epsilon$.  To do so, we first define
$\Sensor{S}{\W}{\Delta}$, which takes an LTL state formula $S$ and a
positive number $\Delta$, and produces an LTL formula:
\[
\Sensor{S}{\W}{\Delta} \defined \Sys{(\Unchanged{\vars{\W \wedge S}})}{(\W \wedge S)}{\Delta}
\]
This formula expresses the system in which $S$ holds throughout every
continuous transition, and all variables in the continuous transition are
unchanged by the discrete transition. The action formula expressing that
all variables in the continuous transition are unchanged is given by
$\Unchanged{\vars{\W~\wedge~S}}$. In the actual Coq implementation, the set
of variables must be supplied manually.

Intuitively, $S$ is intended to express the relationship between the
physical variable that the sensor is tracking and the actual value it
reads.  For a sensor of some physical variable $\X$, this relationship is
$\X - \epsilon \leq \Xsense \leq \X + \epsilon$, where $\Xsense$ is the
sensed value.  However, for our purposes, we actually need an upper bound
on $\X$, which we accomplish by offsetting $\Xsense$ by $\epsilon$:
\[
\Sense{\X}{\Xmax} \defined
\X - \epsilon \leq \Xsense \leq \X + \epsilon~\wedge~\Xmax = \Xsense + \epsilon
\]

In order to satisfy the assumption of the velocity controller, we
instantiate $\SenseA{}$ with $\V$ and $\Vmax$ and need to prove that for
any $\W$, $\Delta$, and $\epsilon \geq 0$,
\begin{equation}
\vdash \Sense{\V}{\Vmax}~\wedge~\Sensor{\Sense{\V}{\Vmax}}{\W}{\Delta} \rightarrow \Always{\V \leq \Vmax}
\label{thm:sense-safe}
\end{equation}
This theorem follows from \textsc{SysInd} and simple reasoning about linear
real arithmetic.

\subsection{Composition}
We are now in a position to compose the sensor module with our velocity
controller.  First, let \SysA{} composition (\SysConjoin{}) be defined by
conjoining corresponding formulas:
\[
\SysConjoinP{\Sys{D_1}{\W_1}{\Delta}}{\Sys{D_2}{\W_2}{\Delta}} \defined \Sys{\left(D_1 \wedge D_2\right)}{\left(\W_1 \wedge W_2\right)}{\Delta}
\]
Note that since all LTL formulas operate on the same state variables,
conjunction is a very general notion of composition.

Using the definition of \SysConjoin{}, we can state the theorem that the
composition of our sensor with our velocity controller satisfies the safety
property $\Always{\V \leq \ub}$ without any assumptions on $\Vmax$:
\[
\vdash \SysConjoinP{\Sensor{\Sense{\V}{\Vmax}}{\W}{\Delta}}{\VelShim} \rightarrow \Always{\V \leq \ub}
\]
This theorem follows immediately from \textsc{SysCompose}
(Theorem~\ref{thm:sys-compose}).  \textsc{SysCompose} states that if the
first system guarantees an invariant, then the second system can assume
that invariant when it proves its safety condition.  The combined system
does not need the assumption; it has been satisfied by the first system,
and has both properties.  Similar to \textsc{SysInd}, \textsc{SysCompose}
abstracts all of the reasoning for manipulating the internals of the
\SysA{} abstraction.  Crucially, when we apply \textsc{SysCompose}, we do
not need to reprove any theorems about the two systems.  Instead we can
simply use the soundness proofs of the components to satisfy the premises
of \textsc{SysCompose}.

\begin{theorem}[\textsc{SysCompose}]
For state formulas $P,Q,I_a,I_b$, action formulas $D_a,D_b$, constant $\Delta \in \R$,
and evolution predicate $\W$, if the following conditions hold:

\begin{enumerate}[label=\roman*), ref=\roman*]
\item
\label{thm:sys-compose-a}
$\entails I_a~\wedge~\Sys{D_a}{\W}{\Delta} \rightarrow \Always{P}$
\item
\label{thm:sys-compose-b}
$\Always{P} \entails I_b~\wedge~\Sys{D_b}{\W}{\Delta} \rightarrow \Always{Q}$
\end{enumerate}
then
\[
\entails I_a~\wedge~I_b~\wedge~\SysConjoinP{\Sys{D_a}{\W}{\Delta}}{\Sys{D_b}{\W}{\Delta}} {\rightarrow} \Always{(P \wedge Q)}
\]
\label{thm:sys-compose}
\end{theorem}

\subsection{Delay Compensation}
When we compose the sensor specification with the velocity controller, we
implicitly assume that the velocity controller can instantaneously read and
compute with the value produced by the sensor module, $\Vmax$.  In reality,
due to communication or computation time, this may not be the case.  It may
be the case that there is some delay between when the sensor module
produces a value and when it can actually be used in the controller's
safety check.  For example, suppose that the sensor module actually outputs
some value, represented by the variable $\Vmaxpre$ that cannot
instantaneously be used in a safety check.  The following system
compensates for this delay
\[
\DelayComp \defined \Sys{D}{\W}{\Delta}
\]
where $\W \defined \dt{\V}\leq\T - g$ as before and
\[
D  \defined \Vmax\tlaprime = \Vmaxpre + \Delta \cdot \mathsf{max}(0, \T\tlaprime - g)
\]
In this system, $D$ uses the current value of $\Vmaxpre$ to compute an
upper bound on $\V$ for the next $\Delta$ time.
%% , and sets $\Vmax$ equal to it. %% , which can then be used during the
%% next discrete transition.  Here, $\Vmax\tlaprime$ is set to a value that
%% will be an upper bound on $\V$ for the next $\Delta$ time.

The correctness property for this system is
\begin{align}
\Always{\V \leq \Vmaxpre} \entails I~\wedge~\DelayComp \rightarrow \Always{\V \leq \Vmax} \\
I \defined \Vmax = \V + \Delta \cdot \mathsf{max}(0, \T - g) \nonumber
\label{thm:delay-safe}
\end{align}

Notice that this property relies on the assumption $\Always{\V \leq
  \Vmaxpre}$.  However, we can use the sensor module above to satisfy this
assumption and use \textsc{SysCompose} to verify the combined system
without any assumptions, again without reproving the properties of the
individual systems:
\[
\entails \SysConjoinP{\Sensor{\Sense{\V}{\Vmaxpre}}{\W}{\Delta}}{\DelayComp} \rightarrow \Always{\V \leq \Vmax}
\]
Now we have a new system that guarantees the assumption of the velocity
controller, so we can compose them and easily prove the theorem:
\[
\entails \SysConjoinP{\SysConjoinP{\Sensor{\Sense{\V}{\Vmaxpre}}{\W}{\Delta}}{\DelayComp}}{\VelShim} \rightarrow \Always{\V \leq \ub}
\]
This approach can be continued for any other sensors or full-blown
controllers that can be specified and verified within the \SysA{}
abstraction.

\subsection{Height controller}
\label{sec:height-shim}

In addition to controlling velocity through a first-derivative, we have
used our deductive approach to control position through a second
derivative.  In this section we describe our implementation of a controller
to enforce an upper bound on height by controlling acceleration.  Note that
if we were able to directly set the velocity then we could reuse the
velocity controller (and its proof) simply by renaming the variables.
Since directly setting velocity is unrealistic, we built a new controller
that bounds position by setting its second derivative.
\[
\HeightShim \defined \Sys{D}{\W}{\Delta}
\]
where
\[
\begin{array}{rl}
\W &\defined \dt{\Y} = \V,~\dt{\V}\leq\T - g \\
D &\defined \quad \tdist{\Vmax}{a_c}{\Delta} {+} \sdist{\Vmax {+} a_c\Delta}{+}  \Ymax \leq \ubY~\wedge~\T\tlaprime {=} \Tproposed \\
   & ~~~~\vee~~\T\tlaprime {=} \amin \\
\tdist{\V}{\T}{\Delta} &\defined \V\cdot\Delta+\frac{\T\Delta^2}{2} \\
\sdist{\V} &\defined -\frac{\V^2}{2\cdot(\amin - g)} \\
a_{c}  &\defined \max(0,\Tproposed - g ) \qquad \amin  < g
\end{array}
\]
The approach is similar to the approach of the velocity controller.  Each
time this controller runs, it checks whether it will be able to stop in
time if it issues the maximum breaking acceleration ($\amin$) the next time
the controller runs.  The function $\mathsf{td}$ computes a conservative
upper-bound on the height at the end of $\Delta$ time and $\mathsf{sd}$
computes the stopping distance assuming $\amin$ breaking acceleration.  We
have formally proven that the height controller guarantees that $\Y$ never
exceeds $\ubY$, under the assumption that $\Ymax$ and $\Vmax$ are bounds on
their respective physical variables.  Formally,
\[
\Always{(\Y \leq \Ymax \wedge \V \leq \Vmax)} \entails \HeightShim \rightarrow \Always{\Y \leq \ubY}
\]
As with the velocity controller, we can compose the height controller with
modules guaranteeing the assumptions that the height controller makes on
$\Ymax$ and $\Vmax$.  Using \textsc{SysCompose}, we can easily prove that
the composed system guarantees $\Always{\Y \leq \ubY}$ from the individual
proofs, without reasoning simultaneously about the entire composed system
and without reproving anything about the individual parts.

Verifying the height controller differs from the velocity controller in two
ways.  First, the differential equations describing the physical evolution
of the system, the controller logic, and therefore the inductive invariant
are all more complex.  This in turn means that the real arithmetic proof
obligations are substantially more intricate.  In practice, this means that
the existing foundational, nonlinear real arithmetic decision procedure is
not able to solve all of the goals, even though the unverified SMT solver
Z3~\cite{demoura2008z3} solves all goals quickly.  Second, the verification
used history variables (omitted from the specification in this paper for
simplicity) to record the value of each physical variable in the last
discrete transition.  We use these values to describe the safety buffer
that the system consumes during the continuous transition.  These variables
do not change the behavior of the controller in any way; they are used only
for reasoning.

\subsubsection*{Benefits of Composition}
When verifying our two controllers, the vast majority of the verification
effort was devoted to foundationally reasoning about real arithmetic proof
obligations.  Our composition technique takes a step towards reducing that
burden.  As a point of comparison with the non-compositional approach, our
first implementation of the height controller was monolithic, including all
of the code for reasoning about delay compensation (but not sensor error).
The result was more complex real arithmetic goals containing larger
expressions and more variables.  When we verified the height controller
compositionally, the arithmetic proof obligations were simpler and, as a
result, required less manual proof effort to simplify the goals into a form
that the foundational decision procedures could handle.  Moreover,
verifying the height controller with the noisy sensor was simply a matter
of combining the independent proofs using \textsc{SysCompose}.  This is a
promising result considering that the number of variables influences the
complexity of the inductive invariant which is directly related to
complexity of automatic verification and difficulty of manual arithmetic
proofs when automation fails.

\subsubsection*{Finding Inductive Invariants}
In general, one of the challenges of formal verification lies in building a
suitable inductive invariant, and hybrid systems are no exception.
However, we have found that developing the inductive invariant is actually
a part of the process of developing the controller.  For example, when
building the velocity controller, we first built the inductive invariant
stating that the thrust is safe until the next time the controller runs.
We then built a controller to compute a thrust that will be safe until the
next time it runs; this followed naturally from the inductive invariant.
This means that we have not found the task of finding an inductive
invariant to be an \emph{additional} burden on top of the necessary task of
building the controller itself. Instead, we found these two tasks to be
naturally related, regardless of whether or not one performs foundational
verification.

\section{From Model to Reality}
\label{sec:experiences}
In addition to modeling and verifying our systems, we also implemented both
the velocity and height controllers to run on a 3D Robotics Iris+.  Running
the system whose model we verify is important because it allows us to
experimentally evaluate the gap between the model and the actual system
that we run.  We can divide this gap into two pieces: the gap due to our
model of the physical world (Section~\ref{sec:world-model}), and the gap
due to our model of the discrete controller
(Section~\ref{sec:discrete-model}).  We conclude by discussing some of the
insights that we gained from running our code on an actual quadcopter
(Section~\ref{sec:results}).

\subsection{A Small Model in a Big World}
\label{sec:world-model}

The primary gap between the physical world and our model lies in the fact
that our model captures only the vertical dimension.  In particular, it
does not model the orientation of the quadcopter and therefore does not
capture the direction of thrust.  However, a model that includes attitude
is a refinement of the world model that our specifications use.  This means
that all traces allowed by a model including attitude are also allowed by
the world model used in our specifications.  As we explained in
Section~\ref{sec:sys}, this is because our specifications model the world
using differential \emph{inequalities} stating that the vertical thrust is
upper-bounded by the thrust produced by the motors.  This relaxation of the
specification means that we must prove properties of a more liberal system,
but it allows us to use our results in the more constrained, richer model
which includes attitude.

The other discrepancies between our model and the real world are common
simplifying assumptions of models for verification purposes.  For example,
modeling external factors such as wind, air resistance, etc. would be
possible by adding extra terms into the differential world description.
Finally, our model also relies on the common assumption of instantaneous
change of discrete variables such as thrust.  In principle, output values
such as thrust actually change over a very small amount of time.  While
this may seem like a reasonable assumption, it nonetheless constitutes a
formal discrepancy.

\subsection{From Relations to Bits}
\label{sec:discrete-model}

Our description of the autpilot architecture in Section~\ref{sec:example}
describes the verified controller as the last piece of code that runs
before signals are sent to the motors.  This is not strictly necessary.
There are advantages and disadvantages to running the verified controller
at different points.


\begin{figure}[t]
\centering

\begin{subfigure}[t]{.3\linewidth}
  \centering
  \begin{tikzpicture}
    \tikzstyle{every node}=[draw=black,thick,font=\bfseries,node distance=0.35cm]
    \tikzstyle{every path}=[draw=black,thick]
    \tikzstyle{wnode}=[minimum width=1cm]

    \node[wnode,text width=2cm,align=center] (existing)  {Existing Control Software} ;

    \node[draw=black,above=of existing,minimum height=0.5cm,xshift=0.7cm] (user) {User} ;
    \node[draw=black,above=of existing,minimum height=0.6cm,xshift=-1cm] (sensor) {Sensors} ;

    \node[wnode,below=of existing] (mixing)  {Mixing Code} ;
    \node[wnode,below=of mixing] (motor)  {Motors} ;

    \newcommand{\quadline}[2]{%
    \foreach \i in {-2,...,1}{%
      \draw[-latex] ([xshift=0.12cm + \i * 0.3 cm]#1.south) -- ([xshift=0.12cm + \i * 0.3 cm]#2.north) ;}}

    \quadline{existing}{mixing}
    \quadline{mixing}{motor}
    \draw[-latex] let \p1 = (user.south),
                      \p2 = (existing.north) in
                  (user.south) -- (\x1,\y2) ;
    \draw[-latex] let \p1 = (sensor.south),
                      \p2 = (existing.north) in
                  ([xshift=0.2cm]sensor.south) -- (\x1+0.2cm,\y2) ;



  \end{tikzpicture}
  \caption{}
  \label{fig:memo15-arch-full-without}
\end{subfigure}
~
\begin{subfigure}[t]{.3\linewidth}
  \centering
  \begin{tikzpicture}
    \tikzstyle{every node}=[draw=black,thick,font=\bfseries,node distance=0.35cm]
    \tikzstyle{every path}=[draw=black,thick]
    \tikzstyle{wnode}=[minimum width=1cm]

    \node[wnode] (mixing)  {Mixing Code} ;
    \node[wnode,above=of mixing,text width=2cm,align=center,yshift=1cm] (existing)  {Existing Control Software} ;


    \node[draw=black,above=of existing,minimum height=0.5cm,xshift=0.7cm] (user) {User} ;
    \node[draw=black,above=of existing,minimum height=0.6cm,xshift=-1cm] (sensor) {Sensors} ;

    \node[wnode,below=of mixing] (motor)  {Motors} ;

    \newcommand{\quadline}[2]{%
    \foreach \i in {-2,...,1}{%
      \draw[-latex] ([xshift=0.12cm + \i * 0.3 cm]#1.south) -- ([xshift=0.12cm + \i * 0.3 cm]#2.north) ;}}

    \quadline{existing}{mixing}
    \quadline{mixing}{motor}
    \node[fill=black,above=of mixing,text=white,align=center,xshift=-.8cm] (mon) {Ctrl} ;
    \draw[-latex] let \p1 = (user.south),
                      \p2 = (existing.north) in
                  (user.south) -- (\x1,\y2) ;
    \draw[-latex] let \p1 = (sensor.south),
                      \p2 = (existing.north) in
                  ([xshift=0.2cm]sensor.south) -- (\x1+0.2cm,\y2) ;
    \draw[-latex] ([xshift=-0.6cm]sensor.south) |- (mon.west) ;
    \draw[-latex] let \p1 = (mon.north) in
                  ([xshift=-0.48cm]existing.south) -- (\x1+0.3cm,\y1) ;


  \end{tikzpicture}
  \caption{}
  \label{fig:memo15-arch-full-before}
\end{subfigure}
~
\begin{subfigure}[t]{.3\linewidth}
  \centering
  \begin{tikzpicture}
    \tikzstyle{every node}=[draw=black,thick,font=\bfseries,node distance=0.35cm]
    \tikzstyle{every path}=[draw=black,thick]
    \tikzstyle{wnode}=[minimum width=1cm]

    \node[fill=black,text=white,text width=2cm,align=center,minimum height=1cm] (mon) at (0,0) {Verified Control} ;
    \node[wnode,above=of mon] (mixing)  {Mixing Code} ;
    \node[wnode,above=of mixing,text width=2cm,align=center] (existing)  {Existing Control Software} ;

    \node[draw=black,above=of existing,minimum height=0.5cm,xshift=0.7cm] (user) {User} ;
    \node[draw=black,above=of existing,minimum height=0.6cm,xshift=-1cm] (sensor) {Sensors} ;

    \node[wnode,below=of mon] (motor)  {Motors} ;

    \newcommand{\quadline}[2]{%
    \foreach \i in {-2,...,1}{%
      \draw[-latex] ([xshift=0.12cm + \i * 0.3 cm]#1.south) -- ([xshift=0.12cm + \i * 0.3 cm]#2.north) ;}}

    \quadline{mon}{motor}
    \quadline{existing}{mixing}
    \quadline{mixing}{mon}
    \draw[-latex] let \p1 = (user.south),
                      \p2 = (existing.north) in
                  (user.south) -- (\x1,\y2) ;
    \draw[-latex] let \p1 = (sensor.south),
                      \p2 = (existing.north) in
                  ([xshift=0.2cm]sensor.south) -- (\x1+0.2cm,\y2) ;
    \draw[-latex] ([xshift=-0.5cm]sensor.south) |- (mon.west) ;


  \end{tikzpicture}
  \caption{}
  \label{fig:memo15-arch-full-after}
\end{subfigure}

\caption{A depiction of UAV architecture~\ref{fig:memo15-arch-full-without}
  without any modification, \ref{fig:memo15-arch-full-before} with our
  controller running before the motor mixing code, and
  \ref{fig:memo15-arch-full-before} with our controller running after the
  motor mixing code. Black boxes denote verified code.}
\label{fig:arch}
\end{figure}

Figure~\ref{fig:memo15-arch-full-without} depicts a version of the
\ardupilot{} architecture without any of our modifications.  The existing
control software takes input from the user and sensors and outputs a
desired throttle, roll torque, pitch torque, and yaw torque to the ``motor
mixer'' module.  This module then computes the signals to send to each of
the four motors to best approximate the desired behavior.  The
approximation is necessary because it is not always possible to achieve all
four desired values simultaneously since the quadcopter relies on
differences between motor speeds to induce non-zero torques.

One place to execute our controller is before the motor mixing module
(Figure~\ref{fig:memo15-arch-full-before}).  At this point, our controller
executes directly on the desired throttle of the higher-level controller.
To meet the interface of our specifications of both the height and velocity
controllers, we must convert this input into a desired vertical thrust
($\Tproposed$).  We must also convert the thrust output by the controllers ($\T$)
into a desired throttle that serves as the input to the mixer module.  We
accomplish both tasks by multiplying the throttle by a constant which we
determined empirically.  We discuss the consequence of this choice in
Section~\ref{sec:results}. As we have already discussed, this will actually
provide an upper bound on vertical acceleration, an acceptable input to our
controllers.  Placing the controller here allows the motor mixer to optimize the engine
outputs to achieve the other parameters (attitude torques) as best it can.
However, it also requires us to trust that the motor mixer module never
exceeds the desired throttle, a property that we believe to hold but have
not formally verified.

Running after the motor mixer (Figure~\ref{fig:memo15-arch-full-after})
allows us to remove the mixer from the trusted computing base.  To meet the
interface at this level, we must translate between the motor signals and
the induced thrust.  We again accomplish this using an empirically
determined constant that we use to scale each of the motor signals.  If the
controller rejects the proposed thrust, then it must compute new signals
for the motors to induce a safe thrust.  There are many ways to achieve a
particular total thrust by adjusting four motor signals.  In order to
minimize the affect of the controller on attitude dynamics, we linearly
scale back each of the motor values to achieve the thrust output by the
controller.

Regardless of where we insert the controller, the trusted computing base
still includes the sensor fusion code that runs on the quadcopter. This
code takes input from sensors and computes an estimation of the state
(e.g. position, velocity, attitude, etc.) of the vehicle. We use this code
to provide bounds ($\Vmax$ and $\Ymax$) on physical variables, in essence
treating the sensor fusion code as an unverified sensor module.  This code
is substantially larger and more complex than the motor mixing code and we
are interested in applying our techniques to reason about it in the future.
We are also trusting our (currently manual) translation of the discrete
controller model from LTL to C code.  This translation includes picking an
appropriate value for $\Delta$, the maximum time between discrete
transitions.  However, any upper bound suffices since our proofs hold for
all $\Delta$.  Finally, we ignore the formal gap between real arithmetic
used in our models and floating-point arithmetic used in the running code.
Future work can investigate closing this formal gap using Coq's libary for
reasoning about floating point computation~\cite{flocq11}.

\subsection{Empirical Results}
\label{sec:results}
Evaluating empirical results of this nature is important when exploring
models.  For example, when we first described our controller logic to an expert
pilot he was concerned that disengaging the motors so harshly might have a
destabilizing effect on the quadcopter.  It was only experimentally that we
learned that this was not the case.

Experimentally, both the velocity and the height controller enforce their
respective safety properties.  The height and velocity controllers allowed
the quadcoptor to go right up to the provided height or velocity bounds.
In some rare cases, the quadcopter went above the bounds, by a small
amount, for example about ten centimeters for a height bound of 30 meters.
We attribute these small violations to un-modeled forces such as wind,
sensor inaccuracy, and inaccuracy in the measured relationship between
throttle/motor signals and thrust induced.  In fact, we found the measured
relationship between signals and thrust to have a significant impact on the
behavior of the quadcopter and was perhaps the greatest source of error
that we noticed.  We were careful to be conservative when measuring these
constants; since our controllers both provide upper bounds, we can safely
err on the side of constants that provide upper bounds on acceleration.
Future work can investigate running our controllers on top of closed-loop
acceleration controllers to avoid the need for these empirical constants.

We flew the quadcopter in both loiter and stabilize modes, and also had the
quadcopter approach the height and velocity bounds from a variety of
velocities and orientations. In loiter mode, the pilot sends desired
velocity commands to the vehicle, while in stabilize mode, the pilot
commands desired attitudes. In all cases, the controllers enforced their
safety properties with rare, small violations, and allowed us to retain
control over the quadcopter.  We never ran both controllers simultaneously
because we have no verification results for this scenario.  Fundamentally,
to compose the controllers we are obliged to show that the controllers do
not conflict with one another, e.g. by requiring different remedial
actions. We investigate this further in Chapter~\ref{chap:emsoft16}.

Also, recall that our height controller is conservative in the way that it
estimates upward thrust: it assumes that the thrust requested by the
higher-level controller would be applied directly in the upward direction,
even if the attitude of the quadcoptor is not upward.  As a result, if the
attitude is not level, our height controller assumes that there is a larger
upward thrust than really occurs, and so it will engage earlier than it
needs to.  We noticed this effect experimentally: when approaching the
height through a non-level attitude, the quadcopter would stop ascending at
a lower height than the actual bound.  Furthermore, when the quadcopter is
at the height bound with the controller engaged and the upward throttle
stick engaged to the maximum, if we start rolling or pitching, the
quadcopter will not only move in the x-y direction, but it will also
descend slightly, since as the orientation changes, the height controller
becomes more conservative.

Finally, we also tried our velocity controller with a small negative
velocity as the bound. With the throttle stick engaged to the maximum, this
caused the quadcopter to land while allowing us to control other aspects of
the flight such as attitude and x-y positioning.
